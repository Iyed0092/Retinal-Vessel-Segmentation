{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33657bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import configparser\n",
    "\n",
    "# TensorFlow Keras imports\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, Dropout, Permute, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model as plot\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# Custom libraries\n",
    "sys.path.insert(0, './lib/')\n",
    "from help_functions import *\n",
    "\n",
    "# Function to obtain data for training/testing (validation)\n",
    "from extract_patches import get_data_training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7662aa",
   "metadata": {},
   "source": [
    "### Defining Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ce2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the neural network\n",
    "def get_unet(n_ch,patch_height,patch_width):\n",
    "    inputs = Input(shape=(n_ch,patch_height,patch_width))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2,up1],axis=1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1,up2], axis=1)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\n",
    "    #\n",
    "    conv6 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv5)\n",
    "    conv6 = Reshape((2,patch_height*patch_width))(conv6)\n",
    "    conv6 = Permute((2,1))(conv6)\n",
    "    ############\n",
    "    conv7 = Activation('softmax')(conv6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv7)\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#========= Load settings from Config file\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('configuration.txt')\n",
    "#patch to the datasets\n",
    "path_data = config.get('data paths', 'path_local')\n",
    "#Experiment name\n",
    "name_experiment = config.get('experiment name', 'name')\n",
    "#training settings\n",
    "N_epochs = int(config.get('training settings', 'N_epochs'))\n",
    "batch_size = int(config.get('training settings', 'batch_size'))\n",
    "\n",
    "\n",
    "\n",
    "#============ Load the data and divided in patches\n",
    "patches_imgs_train, patches_masks_train = get_data_training(\n",
    "    DRIVE_train_imgs_original = path_data + config.get('data paths', 'train_imgs_original'),\n",
    "    DRIVE_train_groudTruth = path_data + config.get('data paths', 'train_groundTruth'),  #masks\n",
    "    patch_height = int(config.get('data attributes', 'patch_height')),\n",
    "    patch_width = int(config.get('data attributes', 'patch_width')),\n",
    "    N_subimgs = int(config.get('training settings', 'N_subimgs')),\n",
    "    inside_FOV = config.getboolean('training settings', 'inside_FOV') #select the patches only inside the FOV  (default == True)\n",
    ")\n",
    "\n",
    "\n",
    "#=========== Construct and save the model arcitecture =====\n",
    "n_ch = patches_imgs_train.shape[1]\n",
    "patch_height = patches_imgs_train.shape[2]\n",
    "patch_width = patches_imgs_train.shape[3]\n",
    "model = get_unet(n_ch, patch_height, patch_width)  #the U-net model\n",
    "print (\"Check: final output of the network:\")\n",
    "print (model.output_shape)\n",
    "\n",
    "# original masks: (batch, 1, 48, 48)\n",
    "patches_masks_train_flat = np.reshape(patches_masks_train, (patches_masks_train.shape[0], -1))  # -> (batch, 2304)\n",
    "patches_masks_train_cat = to_categorical(patches_masks_train_flat, num_classes=2)  # -> (batch, 2304, 2)\n",
    "\n",
    "\n",
    "model.fit(patches_imgs_train, patches_masks_train_cat, epochs=N_epochs, batch_size= batch_size, verbose=2, shuffle=True, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a55f3",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504942d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Python\n",
    "import numpy as np\n",
    "import configparser\n",
    "from matplotlib import pyplot as plt\n",
    "#Keras\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "#scikit learn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "sys.path.insert(0, './lib/')\n",
    "# help_functions.py\n",
    "from help_functions import *\n",
    "# extract_patches.py\n",
    "from extract_patches import recompone\n",
    "from extract_patches import recompone_overlap\n",
    "from extract_patches import paint_border\n",
    "from extract_patches import kill_border\n",
    "from extract_patches import pred_only_FOV\n",
    "from extract_patches import get_data_testing\n",
    "from extract_patches import get_data_testing_overlap\n",
    "# pre_processing.py\n",
    "from pre_processing import my_PreProc\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd961329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#========= CONFIG FILE TO READ FROM =======\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('configuration.txt')\n",
    "#===========================================\n",
    "#run the training on invariant or local\n",
    "path_data = config.get('data paths', 'path_local')\n",
    "\n",
    "#original test images (for FOV selection)\n",
    "DRIVE_test_imgs_original = path_data + config.get('data paths', 'test_imgs_original')\n",
    "test_imgs_orig = load_hdf5(DRIVE_test_imgs_original)\n",
    "full_img_height = test_imgs_orig.shape[2]\n",
    "full_img_width = test_imgs_orig.shape[3]\n",
    "#the border masks provided by the DRIVE\n",
    "DRIVE_test_border_masks = path_data + config.get('data paths', 'test_border_masks')\n",
    "test_border_masks = load_hdf5(DRIVE_test_border_masks)\n",
    "# dimension of the patches\n",
    "patch_height = int(config.get('data attributes', 'patch_height'))\n",
    "patch_width = int(config.get('data attributes', 'patch_width'))\n",
    "#the stride in case output with average\n",
    "stride_height = int(config.get('testing settings', 'stride_height'))\n",
    "stride_width = int(config.get('testing settings', 'stride_width'))\n",
    "assert (stride_height < patch_height and stride_width < patch_width)\n",
    "#model name\n",
    "name_experiment = config.get('experiment name', 'name')\n",
    "path_experiment = './' +name_experiment +'/'\n",
    "#N full images to be predicted\n",
    "Imgs_to_test = int(config.get('testing settings', 'full_images_to_test'))\n",
    "#Grouping of the predicted images\n",
    "N_visual = int(config.get('testing settings', 'N_group_visual'))\n",
    "#====== average mode ===========\n",
    "average_mode = config.getboolean('testing settings', 'average_mode')\n",
    "\n",
    "\n",
    "# #ground truth\n",
    "# gtruth= path_data + config.get('data paths', 'test_groundTruth')\n",
    "# img_truth= load_hdf5(gtruth)\n",
    "# visualize(group_images(test_imgs_orig[0:20,:,:,:],5),'original')#.show()\n",
    "# visualize(group_images(test_border_masks[0:20,:,:,:],5),'borders')#.show()\n",
    "# visualize(group_images(img_truth[0:20,:,:,:],5),'gtruth')#.show()\n",
    "\n",
    "\n",
    "\n",
    "#============ Load the data and divide in patches\n",
    "patches_imgs_test = None\n",
    "new_height = None\n",
    "new_width = None\n",
    "masks_test  = None\n",
    "patches_masks_test = None\n",
    "if average_mode == True:\n",
    "    patches_imgs_test, new_height, new_width, masks_test = get_data_testing_overlap(\n",
    "        DRIVE_test_imgs_original = DRIVE_test_imgs_original,  #original\n",
    "        DRIVE_test_groudTruth = path_data + config.get('data paths', 'test_groundTruth'),  #masks\n",
    "        Imgs_to_test = int(config.get('testing settings', 'full_images_to_test')),\n",
    "        patch_height = patch_height,\n",
    "        patch_width = patch_width,\n",
    "        stride_height = stride_height,\n",
    "        stride_width = stride_width\n",
    "    )\n",
    "else:\n",
    "    patches_imgs_test, patches_masks_test = get_data_testing(\n",
    "        DRIVE_test_imgs_original = DRIVE_test_imgs_original,  #original\n",
    "        DRIVE_test_groudTruth = path_data + config.get('data paths', 'test_groundTruth'),  #masks\n",
    "        Imgs_to_test = int(config.get('testing settings', 'full_images_to_test')),\n",
    "        patch_height = patch_height,\n",
    "        patch_width = patch_width,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "#================ Run the prediction of the patches ==================================\n",
    "#best_last = config.get('testing settings', 'best_last')\n",
    "#Load the saved model\n",
    "#model = model_from_json(open(path_experiment+name_experiment +'_architecture.json').read())\n",
    "#model.load_weights(path_experiment+name_experiment + '_'+best_last+'_weights.h5')\n",
    "#Calculate the predictions\n",
    "predictions = model.predict(patches_imgs_test, batch_size=32, verbose=2)\n",
    "print (\"predicted images size :\")\n",
    "print (predictions.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e832c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_patches_h: 109\n",
      "N_patches_w: 105\n",
      "N_patches_img: 11445\n",
      "According to the dimension inserted, there are 10 full images (of 588x568 each)\n",
      "(10, 1, 588, 568)\n",
      "Orig imgs shape: (10, 1, 584, 565)\n",
      "pred imgs shape: (10, 1, 584, 565)\n",
      "Gtruth imgs shape: (10, 1, 584, 565)\n"
     ]
    }
   ],
   "source": [
    "#===== Convert the prediction arrays in corresponding images\n",
    "pred_patches = pred_to_imgs(predictions, patch_height, patch_width, \"threshold\")\n",
    "\n",
    "\n",
    "\n",
    "#========== Elaborate and visualize the predicted images ====================\n",
    "pred_imgs = None\n",
    "orig_imgs = None\n",
    "gtruth_masks = None\n",
    "if average_mode == True:\n",
    "    pred_imgs = recompone_overlap(pred_patches, new_height, new_width, stride_height, stride_width)# predictions\n",
    "    orig_imgs = my_PreProc(test_imgs_orig[0:pred_imgs.shape[0],:,:,:])    #originals\n",
    "    gtruth_masks = masks_test  #ground truth masks\n",
    "else:\n",
    "    pred_imgs = recompone(pred_patches,13,12)       # predictions\n",
    "    orig_imgs = recompone(patches_imgs_test,13,12)  # originals\n",
    "    gtruth_masks = recompone(patches_masks_test,13,12)  #masks\n",
    "# apply the DRIVE masks on the repdictions #set everything outside the FOV to zero!!\n",
    "kill_border(pred_imgs, test_border_masks)  #DRIVE MASK  #only for visualization\n",
    "## back to original dimensions\n",
    "orig_imgs = orig_imgs[:,:,0:full_img_height,0:full_img_width]\n",
    "pred_imgs = pred_imgs[:,:,0:full_img_height,0:full_img_width]\n",
    "gtruth_masks = gtruth_masks[:,:,0:full_img_height,0:full_img_width]\n",
    "print (\"Orig imgs shape: \" +str(orig_imgs.shape))\n",
    "print (\"pred imgs shape: \" +str(pred_imgs.shape))\n",
    "print (\"Gtruth imgs shape: \" +str(gtruth_masks.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d030924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the folder exists\n",
    "folder = \"./test/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce706af",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(group_images(orig_imgs,N_visual),path_experiment+\"all_originals\")#.show()\n",
    "visualize(group_images(gtruth_masks,N_visual),path_experiment+\"all_groundTruths\")#.show()\n",
    "visualize(group_images(pred_imgs,N_visual),path_experiment+\"all_predictions\")#.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#visualize results comparing mask and prediction:\n",
    "assert (orig_imgs.shape[0]==pred_imgs.shape[0] and orig_imgs.shape[0]==gtruth_masks.shape[0])\n",
    "N_predicted = orig_imgs.shape[0]\n",
    "group = N_visual\n",
    "assert (N_predicted%group==0)\n",
    "for i in range(int(N_predicted/group)):\n",
    "    orig_stripe = group_images(orig_imgs[i*group:(i*group)+group,:,:,:],group)\n",
    "    masks_stripe = group_images(gtruth_masks[i*group:(i*group)+group,:,:,:],group)\n",
    "    pred_stripe = group_images(pred_imgs[i*group:(i*group)+group,:,:,:],group)\n",
    "    total_img = np.concatenate((orig_stripe,masks_stripe,pred_stripe),axis=0)\n",
    "    visualize(total_img,path_experiment+name_experiment +\"_Original_GroundTruth_Prediction\"+str(i))#.show()\n",
    "\n",
    "\n",
    "#====== Evaluate the results\n",
    "print (\"\\n\\n========  Evaluate the results =======================\")\n",
    "#predictions only inside the FOV\n",
    "y_scores, y_true = pred_only_FOV(pred_imgs,gtruth_masks, test_border_masks)  #returns data only inside the FOV\n",
    "print (\"Calculating results only inside the FOV:\")\n",
    "print (\"y scores pixels: \" +str(y_scores.shape[0]) +\" (radius 270: 270*270*3.14==228906), including background around retina: \" +str(pred_imgs.shape[0]*pred_imgs.shape[2]*pred_imgs.shape[3]) +\" (584*565==329960)\")\n",
    "print (\"y true pixels: \" +str(y_true.shape[0]) +\" (radius 270: 270*270*3.14==228906), including background around retina: \" +str(gtruth_masks.shape[2]*gtruth_masks.shape[3]*gtruth_masks.shape[0])+\" (584*565==329960)\")\n",
    "\n",
    "#Area under the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve((y_true), y_scores)\n",
    "AUC_ROC = roc_auc_score(y_true, y_scores)\n",
    "# test_integral = np.trapz(tpr,fpr) #trapz is numpy integration\n",
    "print (\"\\nArea under the ROC curve: \" +str(AUC_ROC))\n",
    "roc_curve =plt.figure()\n",
    "plt.plot(fpr,tpr,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_ROC)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel(\"FPR (False Positive Rate)\")\n",
    "plt.ylabel(\"TPR (True Positive Rate)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(path_experiment+\"ROC.png\")\n",
    "\n",
    "#Precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "precision = np.fliplr([precision])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "recall = np.fliplr([recall])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "AUC_prec_rec = np.trapz(precision,recall)\n",
    "print (\"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec))\n",
    "prec_rec_curve = plt.figure()\n",
    "plt.plot(recall,precision,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_prec_rec)\n",
    "plt.title('Precision - Recall curve')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(path_experiment+\"Precision_recall.png\")\n",
    "\n",
    "#Confusion matrix\n",
    "threshold_confusion = 0.5\n",
    "print (\"\\nConfusion matrix:  Custom threshold (for positive) of \" +str(threshold_confusion))\n",
    "y_pred = np.empty((y_scores.shape[0]))\n",
    "for i in range(y_scores.shape[0]):\n",
    "    if y_scores[i]>=threshold_confusion:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "print (confusion)\n",
    "accuracy = 0\n",
    "if float(np.sum(confusion))!=0:\n",
    "    accuracy = float(confusion[0,0]+confusion[1,1])/float(np.sum(confusion))\n",
    "print (\"Global Accuracy: \" +str(accuracy))\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "print (\"Specificity: \" +str(specificity))\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "print (\"Sensitivity: \" +str(sensitivity))\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "print (\"Precision: \" +str(precision))\n",
    "\n",
    "#Jaccard similarity index\n",
    "jaccard_index = jaccard_score(y_true, y_pred, normalize=True)\n",
    "print (\"\\nJaccard similarity score: \" +str(jaccard_index))\n",
    "\n",
    "#F1 score\n",
    "F1_score = f1_score(y_true, y_pred, labels=None, average='binary', sample_weight=None)\n",
    "print (\"\\nF1 score (F-measure): \" +str(F1_score))\n",
    "\n",
    "#Save the results\n",
    "file_perf = open(path_experiment+'performances.txt', 'w')\n",
    "file_perf.write(\"Area under the ROC curve: \"+str(AUC_ROC)\n",
    "                + \"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec)\n",
    "                + \"\\nJaccard similarity score: \" +str(jaccard_index)\n",
    "                + \"\\nF1 score (F-measure): \" +str(F1_score)\n",
    "                +\"\\n\\nConfusion matrix:\"\n",
    "                +str(confusion)\n",
    "                +\"\\nACCURACY: \" +str(accuracy)\n",
    "                +\"\\nSENSITIVITY: \" +str(sensitivity)\n",
    "                +\"\\nSPECIFICITY: \" +str(specificity)\n",
    "                +\"\\nPRECISION: \" +str(precision)\n",
    "                )\n",
    "file_perf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
